<!DOCTYPE html>
<html>
<!-- bwedgar.github.io/PushToTelescope   -->

<head>

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="apple-touch-icon" href="launch3.png">
  <link rel="apple-touch-startup-image" href="launch3.png">

  <link rel="manifest" href="manifest.json">
  <link rel="canonical" href="https://bwedgar.github.io/PushToTelescope" />

  <title>Document</title>
  <meta name="apple-mobile-web-app-title" content="Push To Telescope">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">


  <script src="https://bwedgar.github.io/buttons/buttons.js"></script>
  <!-- <script src="../buttons/buttons.js"></script> -->

  <!-- <script src="sw.js"></script> -->

</head>


<body>
  <main id="camera">
    <!-- Camera sensor -->
    <canvas id="camera--sensor"></canvas>
    <!-- Camera view -->
    <video id="camera--view" autoplay playsinline></video>
    <!-- Camera output -->
    <img src="//:0" alt="" id="camera--output">
    <!-- Camera trigger -->
    <button id="camera--trigger">Take a picture 2</button>
  </main>

  <script>
    var b = Buttons
    // Set constraints for the video stream
    var constraints = {
      video: {
        facingMode: "environment"
      },
      audio: false
    };
    // Define constants
    const cameraView = document.querySelector("#camera--view"),
      cameraOutput = document.querySelector("#camera--output"),
      cameraSensor = document.querySelector("#camera--sensor"),
      cameraTrigger = document.querySelector("#camera--trigger")
    // Access the device camera and stream to cameraView
    function cameraStart() {
      navigator.mediaDevices
        .getUserMedia(constraints)
        .then(function(stream) {
          track = stream.getTracks()[0];
          cameraView.srcObject = stream;
        })
        .catch(function(error) {
          console.error("Oops. Something is broken.", error);
        });
    }
    // Take a picture when cameraTrigger is tapped
    cameraTrigger.onclick = function() {
      cameraSensor.width = cameraView.videoWidth;
      cameraSensor.height = cameraView.videoHeight;
      ctx = cameraSensor.getContext("2d")
      ctx.drawImage(cameraView,100, 100);
      cameraOutput.src = cameraSensor.toDataURL("image/webp");
      cameraOutput.classList.add("taken");
      alert(ctx.width)
      if (ctx.width > 0) {
        var imageData = ctx.getImageData(0, 0, cameraSensor.width, cameraSensor.height);
        var dataArr = imageData.data;

        for (var i = 0; i < dataArr.length; i += 4) {
          var r = dataArr[i]; // Red color lies between 0 and 255
          var g = dataArr[i + 1]; // Green color lies between 0 and 255
          var b = dataArr[i + 2]; // Blue color lies between 0 and 255
          var a = dataArr[i + 3]; // Transparency lies between 0 and 255

          var invertedRed = 255 - r;
          var invertedGreen = 255 - g;
          var invertedBlue = 255 - b;

          dataArr[i] = invertedRed;
          dataArr[i + 1] = invertedGreen;
          dataArr[i + 2] = invertedBlue;
        }

        cameraSensor.putImageData(imageData, 0, 0);
        alert("added negative")
      }

    };
    // Start the video stream when the window loads
    window.addEventListener("load", cameraStart, false);
  </script>
</body>

</html>
